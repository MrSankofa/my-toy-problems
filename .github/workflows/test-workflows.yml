name: Java, JavaScript, and Python CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    permissions:
      checks: write
      pull-requests: write

    steps:
      # Checkout the repository
      - uses: actions/checkout@v2

      # Set up Java environment
      - name: Set up JDK 11
        uses: actions/setup-java@v2
        with:
          java-version: '11'
          distribution: 'adopt'

      # Build and test Java with Maven
      - name: Build and test Java with Maven
        run: mvn -B verify
        working-directory: ./java

      # Publish Java test reports
      - name: Publish Java Test Report
        uses: mikepenz/action-junit-report@v3
        if: always()
        with:
          report_paths: './java/target/surefire-reports/TEST-*.xml'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Set up Node.js environment for JavaScript
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'

      # Install JavaScript dependencies
      - name: Install JavaScript dependencies
        run: npm install
        working-directory: ./javascript

      # Run JavaScript tests
      - name: Run JavaScript tests
        run: npm test -- --json --outputFile=jest-results.json
        working-directory: ./javascript

      # Parse JavaScript test results
      - name: Parse JavaScript Test Results
        if: always()
        run: |
          total_js_tests=$(cat ./javascript/jest-results.json | jq '.numTotalTests')
          passed_js_tests=$(cat ./javascript/jest-results.json | jq '.numPassedTests')
          failed_js_tests=$(cat ./javascript/jest-results.json | jq '.numFailedTests')
          skipped_js_tests=$(cat ./javascript/jest-results.json | jq '.numPendingTests')

          echo "total_js_tests=${total_js_tests}" >> $GITHUB_ENV
          echo "passed_js_tests=${passed_js_tests}" >> $GITHUB_ENV
          echo "failed_js_tests=${failed_js_tests}" >> $GITHUB_ENV
          echo "skipped_js_tests=${skipped_js_tests}" >> $GITHUB_ENV

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # Install Python dependencies
      - name: Install Python dependencies
        run: pip install -r requirements.txt
        working-directory: ./python

      # Run Python tests with pytest
      - name: Run Python tests
        run: pytest --json-report --json-report-file=pytest-report.json
        working-directory: ./python

      # Parse Python test results
      - name: Parse Python Test Results
        if: always()
        run: |
          total_py_tests=$(cat ./python/pytest-report.json | jq '.summary.num_tests')
          passed_py_tests=$(cat ./python/pytest-report.json | jq '.summary.passed')
          failed_py_tests=$(cat ./python/pytest-report.json | jq '.summary.failed')
          skipped_py_tests=$(cat ./python/pytest-report.json | jq '.summary.skipped')

          echo "total_py_tests=${total_py_tests}" >> $GITHUB_ENV
          echo "passed_py_tests=${passed_py_tests}" >> $GITHUB_ENV
          echo "failed_py_tests=${failed_py_tests}" >> $GITHUB_ENV
          echo "skipped_py_tests=${skipped_py_tests}" >> $GITHUB_ENV

      # Post Combined Test Summary
      - name: Post Test Summary
        if: always()
        run: |
          # Process Java test results
          if [ -d "./java/target/surefire-reports" ]; then
            total_java_tests=$(find ./java/target/surefire-reports -name 'TEST-*.xml' | xargs grep -h "<testcase" | wc -l)
            failed_java_tests=$(find ./java/target/surefire-reports -name 'TEST-*.xml' | xargs grep -h "<failure" | wc -l)
            skipped_java_tests=$(find ./java/target/surefire-reports -name 'TEST-*.xml' | xargs grep -h "<skipped" | wc -l)
            passed_java_tests=$((total_java_tests - failed_java_tests - skipped_java_tests))
          else
            total_java_tests=0
            failed_java_tests=0
            skipped_java_tests=0
            passed_java_tests=0
          fi

          # Fetch JavaScript test results from environment variables
          total_js_tests=${{ env.total_js_tests }}
          passed_js_tests=${{ env.passed_js_tests }}
          failed_js_tests=${{ env.failed_js_tests }}
          skipped_js_tests=${{ env.skipped_js_tests }}

          # Fetch Python test results from environment variables
          total_py_tests=${{ env.total_py_tests }}
          passed_py_tests=${{ env.passed_py_tests }}
          failed_py_tests=${{ env.failed_py_tests }}
          skipped_py_tests=${{ env.skipped_py_tests }}

          # Post combined summary
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "✨ **Build Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          
          # Java Test Results
          echo "### Java Tests" >> $GITHUB_STEP_SUMMARY
          echo "🎯 **Total Tests**: ${total_java_tests}" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Passed Tests**: ${passed_java_tests}" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ **Skipped Tests**: ${skipped_java_tests}" >> $GITHUB_STEP_SUMMARY
          echo "❌ **Failed Tests**: ${failed_java_tests}" >> $GITHUB_STEP_SUMMARY

          # JavaScript Test Results
          echo "### JavaScript Tests" >> $GITHUB_STEP_SUMMARY
          echo "🎯 **Total Tests**: ${total_js_tests}" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Passed Tests**: ${passed_js_tests}" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ **Skipped Tests**: ${skipped_js_tests}" >> $GITHUB_STEP_SUMMARY
          echo "❌ **Failed Tests**: ${failed_js_tests}" >> $GITHUB_STEP_SUMMARY

          # Python Test Results
          echo "### Python Tests" >> $GITHUB_STEP_SUMMARY
          echo "🎯 **Total Tests**: ${total_py_tests}" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Passed Tests**: ${passed_py_tests}" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ **Skipped Tests**: ${skipped_py_tests}" >> $GITHUB_STEP_SUMMARY
          echo "❌ **Failed Tests**: ${failed_py_tests}" >> $GITHUB_STEP_SUMMARY
